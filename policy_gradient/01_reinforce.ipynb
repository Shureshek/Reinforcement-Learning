{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVkCC1iri2SN"
   },
   "source": [
    "## HW 4: Policy gradient\n",
    "_Reference: based on Practical RL course by YSDA_\n",
    "\n",
    "In this notebook you have to master Policy gradient Q-learning and apply it to familiar (and not so familiar) RL problems once again.\n",
    "\n",
    "To get used to `gymnasium` package, please, refer to the [documentation](https://gymnasium.farama.org/introduction/basic_usage/).\n",
    "\n",
    "\n",
    "In the end of the notebook, please, copy the functions you have implemented to the template file and submit it to the Contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.718234Z",
     "start_time": "2025-09-28T12:13:27.715401Z"
    },
    "id": "7UYczVTli2Sb"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.803791Z",
     "start_time": "2025-09-28T12:13:27.733746Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "XPKYrIlai2Sf",
    "outputId": "2e044ee7-3baa-4bd7-a214-23b7225a88b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19c828e9490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75eHkuwTi2Si"
   },
   "source": [
    "# Building the network for Policy Gradient (REINFORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_TFCmsWi2Sj"
   },
   "source": [
    "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
    "\n",
    "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
    "We'll use softmax or log-softmax where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.821515Z",
     "start_time": "2025-09-28T12:13:27.817340Z"
    },
    "id": "sY2THBWfi2Sl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.844491Z",
     "start_time": "2025-09-28T12:13:27.840982Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.857811Z",
     "start_time": "2025-09-28T12:13:27.855540Z"
    },
    "id": "8_pYr7PZi2Sn"
   },
   "outputs": [],
   "source": [
    "# Build a simple neural network that predicts policy logits.\n",
    "# Keep it simple: CartPole isn't worth deep architectures.\n",
    "\n",
    "model = DQN(state_dim[0], n_actions)\n",
    "assert model is not None, \"model is not defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.871193Z",
     "start_time": "2025-09-28T12:13:27.867165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_states_batch.shape: (5, 4)\n",
      "example_logits.shape: torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "# do not change the code block below\n",
    "batch_size_for_test = 5\n",
    "example_states_batch = np.array([env.reset()[0] for _ in range(5)])\n",
    "print(f\"example_states_batch.shape: {example_states_batch.shape}\")\n",
    "assert example_states_batch.shape == (batch_size_for_test, state_dim[0])\n",
    "\n",
    "example_logits = model(torch.from_numpy(example_states_batch))\n",
    "print(f\"example_logits.shape: {example_logits.shape}\")\n",
    "assert example_logits.shape == (batch_size_for_test, n_actions)\n",
    "# do not change the code block above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y80qbQFi2Sq"
   },
   "source": [
    "#### Predicting the action probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12PjRu0mi2Sr"
   },
   "source": [
    "Note: **output value of this function is not a torch tensor, it's a numpy array.**\n",
    "\n",
    "So, here gradient calculation is not needed.\n",
    "\n",
    "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
    "to suppress gradient calculation.\n",
    "\n",
    "Also, `.detach()` can be used instead, but there is a difference:\n",
    "\n",
    "* With `.detach()` computational graph is built but then disconnected from a particular tensor, so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
    "* In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.887714Z",
     "start_time": "2025-09-28T12:13:27.884208Z"
    },
    "id": "d5B5JuXCi2St"
   },
   "outputs": [],
   "source": [
    "def predict_probs(states, model):\n",
    "    \"\"\"\n",
    "    Predict action probabilities given states.\n",
    "    :param states: numpy array of shape [batch, state_shape]\n",
    "    :param model: torch model\n",
    "    :returns: numpy array of shape [batch, n_actions]\n",
    "    \"\"\"\n",
    "    # convert states, compute logits, use softmax to get probability\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "\n",
    "    with torch.no_grad():\n",
    "        states = torch.from_numpy(states).float()\n",
    "        logits = model(states)\n",
    "        probs = nn.functional.softmax(logits, dim=1).numpy()\n",
    "    assert probs is not None, \"probs is not defined\"\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.903402Z",
     "start_time": "2025-09-28T12:13:27.898898Z"
    },
    "id": "Obkl_jCii2Sv"
   },
   "outputs": [],
   "source": [
    "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
    "test_probas = predict_probs(test_states, model)\n",
    "assert isinstance(test_probas, np.ndarray), \\\n",
    "    \"you must return np array and not %s\" % type(test_probas)\n",
    "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
    "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
    "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be6AYf8gi2Sw"
   },
   "source": [
    "### Play the game\n",
    "\n",
    "We can now use our newly built agent to play the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.917037Z",
     "start_time": "2025-09-28T12:13:27.913734Z"
    },
    "id": "8LOUUvnki2Sx"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a full session with REINFORCE agent.\n",
    "    Returns sequences of states, actions, and rewards.\n",
    "    \"\"\"\n",
    "    # arrays to record session\n",
    "    states, actions, rewards = [], [], []\n",
    "    s, info = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # action probabilities array aka pi(a|s)\n",
    "        action_probs = predict_probs(np.array([s]), model)[0]\n",
    "\n",
    "        # Sample action with given probabilities.\n",
    "        a = np.random.choice(n_actions, p=action_probs)\n",
    "        new_s, r, done, truncated, info = env.step(a)\n",
    "\n",
    "        # record session history to train later\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.945765Z",
     "start_time": "2025-09-28T12:13:27.934583Z"
    },
    "id": "5sdENWJAi2Sz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.00562558,  0.03272485, -0.02474253,  0.04651885], dtype=float32), array([-0.00497108, -0.16203372, -0.02381216,  0.33129373], dtype=float32), array([-0.00821175,  0.03341894, -0.01718628,  0.03119775], dtype=float32), array([-0.00754337,  0.22878309, -0.01656233, -0.2668577 ], dtype=float32), array([-0.00296771,  0.03390137, -0.02189948,  0.02055566], dtype=float32), array([-0.00228969, -0.16089979, -0.02148837,  0.3062494 ], dtype=float32), array([-0.00550768, -0.35570905, -0.01536338,  0.59207875], dtype=float32), array([-0.01262186, -0.55061257, -0.00352181,  0.8798829 ], dtype=float32), array([-0.02363411, -0.35544297,  0.01407585,  0.58609486], dtype=float32), array([-0.03074297, -0.5507592 ,  0.02579775,  0.88317835], dtype=float32), array([-0.04175816, -0.3559969 ,  0.04346132,  0.59871584], dtype=float32), array([-0.0488781 , -0.16150916,  0.05543564,  0.32003328], dtype=float32), array([-0.05210828,  0.0327813 ,  0.0618363 ,  0.04533503], dtype=float32), array([-0.05145265,  0.22696455,  0.062743  , -0.22721486], dtype=float32), array([-0.04691336,  0.42113632,  0.0581987 , -0.49946508], dtype=float32), array([-0.03849063,  0.22524425,  0.0482094 , -0.1890237 ], dtype=float32), array([-0.03398575,  0.41964453,  0.04442893, -0.46611723], dtype=float32), array([-0.02559286,  0.2239239 ,  0.03510658, -0.15976821], dtype=float32), array([-0.02111438,  0.0283174 ,  0.03191122,  0.14377998], dtype=float32), array([-0.02054803,  0.22296815,  0.03478682, -0.1386672 ], dtype=float32), array([-0.01608867,  0.41757503,  0.03201347, -0.42017567], dtype=float32), array([-0.00773717,  0.22201446,  0.02360996, -0.11757473], dtype=float32), array([-0.00329688,  0.02656232,  0.02125847,  0.18246245], dtype=float32), array([-0.00276563, -0.16885728,  0.02490771,  0.4817751 ], dtype=float32), array([-0.00614278,  0.02590442,  0.03454322,  0.19704531], dtype=float32), array([-0.00562469, -0.16969416,  0.03848412,  0.5004218 ], dtype=float32), array([-0.00901857, -0.3653369 ,  0.04849256,  0.8049802 ], dtype=float32), array([-0.01632531, -0.17091209,  0.06459216,  0.52793705], dtype=float32), array([-0.01974355,  0.02324445,  0.07515091,  0.25628644], dtype=float32), array([-0.01927866,  0.21721749,  0.08027663, -0.0117783 ], dtype=float32), array([-0.01493432,  0.41110188,  0.08004107, -0.2780923 ], dtype=float32), array([-0.00671228,  0.2149347 ,  0.07447922,  0.03872333], dtype=float32), array([-0.00241358,  0.01882812,  0.07525369,  0.35394436], dtype=float32), array([-0.00203702, -0.17727871,  0.08233257,  0.6693758 ], dtype=float32), array([-0.0055826 ,  0.0166078 ,  0.09572009,  0.40370962], dtype=float32), array([-0.00525044,  0.21025112,  0.10379428,  0.14267303], dtype=float32), array([-0.00104542,  0.40374526,  0.10664774, -0.11554538], dtype=float32), array([0.00702949, 0.20726967, 0.10433684, 0.20878862], dtype=float32), array([0.01117488, 0.01082256, 0.10851261, 0.53247625], dtype=float32), array([ 0.01139133, -0.18564487,  0.11916213,  0.8572841 ], dtype=float32), array([ 0.00767844, -0.38217118,  0.13630782,  1.184934  ], dtype=float32), array([ 3.5011828e-05, -1.8905474e-01,  1.6000649e-01,  9.3789673e-01],\n",
      "      dtype=float32), array([-0.00374608,  0.00359036,  0.17876443,  0.6994617 ], dtype=float32), array([-0.00367428, -0.19350022,  0.19275366,  1.0426636 ], dtype=float32)] [0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1] [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "states, actions, rewards = generate_session(env)\n",
    "print(states, actions, rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG5hLg-3i2S0"
   },
   "source": [
    "### Computing cumulative rewards\n",
    "\n",
    "To work with sequential environments we need the cumulative discounted reward for known for every state. To compute it we can **roll back** from the end of the session to the beginning and compute the discounted cumulative reward as following:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
    "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
    "&= r_t + \\gamma * G_{t + 1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.964262Z",
     "start_time": "2025-09-28T12:13:27.960849Z"
    },
    "id": "AoWX9gvai2S0"
   },
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards,  # rewards at each step\n",
    "                           gamma=0.99  # discount for reward\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    Take a list of immediate rewards r(s,a) for the whole session\n",
    "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
    "\n",
    "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
    "\n",
    "    A simple way to compute cumulative rewards is to iterate from the last\n",
    "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
    "\n",
    "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
    "    \"\"\"\n",
    "    # YOUR CODE GOES HERE\n",
    "    cumulative_rewards = []\n",
    "    g = 0\n",
    "    for r in rewards[::-1]:\n",
    "        g = g * gamma + r\n",
    "        cumulative_rewards.append(g)\n",
    "\n",
    "    cumulative_rewards.reverse()\n",
    "\n",
    "    assert cumulative_rewards is not None, \"cumulative_rewards is not defined\"\n",
    "\n",
    "    return cumulative_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:27.991019Z",
     "start_time": "2025-09-28T12:13:27.987517Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DX39wcUi2S3",
    "outputId": "9916590d-b093-4c5b-dd84-4ed9ed4b2ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks good!\n"
     ]
    }
   ],
   "source": [
    "get_cumulative_rewards(rewards)\n",
    "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
    "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
    "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
    "assert np.allclose(\n",
    "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
    "    [0, 0, 1, 2, 3, 4, 0])\n",
    "print(\"looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evLt5DJji2S_"
   },
   "source": [
    "### Loss function and updates\n",
    "\n",
    "We now need to define objective and update over policy gradient.\n",
    "\n",
    "Our objective function is\n",
    "\n",
    "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
    "\n",
    "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
    "\n",
    "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "\n",
    "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
    "\n",
    "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "\n",
    "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient.\n",
    "\n",
    "Final loss should also include the entropy regularization term $H(\\pi_\\theta (a_i \\mid s_i))$ to enforce the exploration:\n",
    "\n",
    "$$\n",
    "L = -\\hat J(\\theta) - \\lambda H(\\pi_\\theta (a_i \\mid s_i)),\n",
    "$$\n",
    "where $\\lambda$ is the `entropy_coef`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:28.007546Z",
     "start_time": "2025-09-28T12:13:28.004036Z"
    },
    "id": "_hLjxTVLi2TB"
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y_tensor, ndims):\n",
    "    \"\"\" helper: take an integer vector and convert it to 1-hot matrix. \"\"\"\n",
    "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    y_one_hot = torch.zeros(\n",
    "        y_tensor.size()[0], ndims).scatter_(1, y_tensor, 1)\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:28.028618Z",
     "start_time": "2025-09-28T12:13:28.024614Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(logits, actions, rewards, n_actions=n_actions, gamma=0.99, entropy_coef=1e-2):\n",
    "    \"\"\"\n",
    "    Compute the loss for the REINFORCE algorithm.\n",
    "    \"\"\"\n",
    "    actions = torch.tensor(actions, dtype=torch.int32)\n",
    "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
    "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
    "\n",
    "    probs = nn.functional.softmax(logits, dim=1)\n",
    "    assert probs is not None, \"probs is not defined\"\n",
    "\n",
    "    log_probs = nn.functional.log_softmax(logits, dim=1)\n",
    "    assert log_probs is not None, \"log_probs is not defined\"\n",
    "\n",
    "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
    "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
    "\n",
    "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
    "    log_probs_for_actions = torch.sum(log_probs * to_one_hot(actions, n_actions), dim=1)\n",
    "    assert log_probs_for_actions is not None, \"log_probs_for_actions is not defined\"\n",
    "    J_hat = torch.mean(log_probs_for_actions * cumulative_returns)\n",
    "    assert J_hat is not None, \"J_hat is not defined\"\n",
    "    \n",
    "    # Compute loss here. Don't forget entropy regularization with `entropy_coef`\n",
    "    entropy = -torch.sum(probs * log_probs, dim=1).mean()\n",
    "    assert entropy is not None, \"entropy is not defined\"\n",
    "    loss = -J_hat - entropy_coef * entropy\n",
    "    assert loss is not None, \"loss is not defined\"\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:13:28.041011Z",
     "start_time": "2025-09-28T12:13:28.037168Z"
    },
    "id": "1C8ZSizji2TD"
   },
   "outputs": [],
   "source": [
    "# Your code: define optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
    "    \"\"\"\n",
    "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
    "    Updates agent's weights by following the policy gradient above.\n",
    "    Please use Adam optimizer with default parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    states = torch.tensor(states, dtype=torch.float32)\n",
    "    logits = model(states)\n",
    "    # cast everything into torch tensors\n",
    "    loss = get_loss(logits, actions, rewards, n_actions=n_actions, gamma=gamma, entropy_coef=entropy_coef)\n",
    "    # Gradient descent step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # technical: return session rewards to print them later\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-WWsbl5i2TE"
   },
   "source": [
    "### The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:14:10.594078Z",
     "start_time": "2025-09-28T12:13:28.051634Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckHj5sXBi2TE",
    "outputId": "017d3bcd-0d01-4632-ed1c-60642792cddf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward:17.550\n",
      "mean reward:15.150\n",
      "mean reward:27.870\n",
      "mean reward:53.590\n",
      "mean reward:87.520\n",
      "mean reward:172.600\n",
      "mean reward:117.400\n",
      "mean reward:176.260\n",
      "mean reward:109.020\n",
      "mean reward:161.080\n",
      "mean reward:145.300\n",
      "mean reward:187.360\n",
      "mean reward:252.440\n",
      "mean reward:463.370\n",
      "mean reward:770.650\n",
      "mean reward:900.420\n",
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    rewards = [train_on_session(*generate_session(env), entropy_coef=1e-3) for _ in range(100)]  # generate new sessions\n",
    "\n",
    "    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n",
    "\n",
    "    if np.mean(rewards) > 800:\n",
    "        print(\"You Win!\")  # but you can train even further\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bg__sQeti2TF"
   },
   "source": [
    "### Watch the video of your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:14:10.604173Z",
     "start_time": "2025-09-28T12:14:10.601660Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:14:12.460623Z",
     "start_time": "2025-09-28T12:14:10.616151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-0.mp4\n",
      "Moviepy - Building video E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready E:\\Coding\\girafe-ai\\ml-course\\homeworks\\hw04_policy_gradient\\videos/rl-video-episode-1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.utils.save_video import save_video\n",
    "from moviepy.config import change_settings\n",
    "change_settings({\"FFMPEG_BINARY\": r\"C:\\Program Files\\ffmpeg\\bin\\ffmpeg.exe\"})\n",
    "\n",
    "env_for_video = gym.make(\"CartPole-v1\", render_mode=\"rgb_array_list\")\n",
    "n_actions = env_for_video.action_space.n\n",
    "\n",
    "episode_index = 0\n",
    "step_starting_index = 0\n",
    "\n",
    "obs, info = env_for_video.reset()\n",
    "\n",
    "for step_index in range(800):\n",
    "    probs = predict_probs(np.array([obs]), model)[0]\n",
    "    action = np.random.choice(n_actions, p=probs)\n",
    "\n",
    "    obs, reward, terminated, truncated, info = env_for_video.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "    if done or step_index == 799:\n",
    "        # env_for_video.render() now returns the LIST of frames accumulated so far\n",
    "        frames = env_for_video.render()\n",
    "        os.makedirs(\"videos\", exist_ok=True)\n",
    "        save_video(\n",
    "            frames, \"videos\",\n",
    "            fps=env_for_video.metadata.get(\"render_fps\", 30),\n",
    "            step_starting_index=step_starting_index,\n",
    "            episode_index=episode_index,\n",
    "        )\n",
    "        episode_index += 1\n",
    "        step_starting_index = step_index + 1\n",
    "        obs, info = env_for_video.reset()\n",
    "\n",
    "env_for_video.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Finally, copy the `predict_probs`, `get_cumulative_rewards` and `get_loss` to the template and submit them to the Contest.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus part (no points, just for the interested ones)\n",
    "\n",
    "Try solving the `Acrobot-v1` environment. It is more complex than regular `CartPole-v1`, so the default Policy Gradient (REINFORCE) algorithm might not work. Maybe the baseline idea could help...\n",
    "\n",
    "![Acrobot](https://gymnasium.farama.org/_images/acrobot.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T12:14:12.595684Z",
     "start_time": "2025-09-28T12:14:12.471483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19ccec3c320>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"Acrobot-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
